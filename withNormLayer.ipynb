{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Learning Rate | Batch Size | Epoch | Training Loss | Training Accuracy | Validation Loss | Validation Accuracy |\n",
      " 0.001\t\t    32\t       1/3 \t 2.0308 \t    0.3012 \t    1.3155 \t      0.7412\n",
      " 0.001\t\t    32\t       2/3 \t 1.4850 \t    0.5730 \t    0.9155 \t      0.8118\n",
      " 0.001\t\t    32\t       3/3 \t 1.1887 \t    0.6769 \t    0.7168 \t      0.8427\n",
      " 0.001\t\t    64\t       1/3 \t 2.0371 \t    0.2966 \t    1.3564 \t      0.7371\n",
      " 0.001\t\t    64\t       2/3 \t 1.5100 \t    0.5725 \t    0.9524 \t      0.8054\n",
      " 0.001\t\t    64\t       3/3 \t 1.2196 \t    0.6688 \t    0.7463 \t      0.8401\n",
      " 0.001\t\t    128\t       1/3 \t 2.0724 \t    0.2865 \t    1.3995 \t      0.7410\n",
      " 0.001\t\t    128\t       2/3 \t 1.5365 \t    0.5596 \t    0.9656 \t      0.8070\n",
      " 0.001\t\t    128\t       3/3 \t 1.2247 \t    0.6649 \t    0.7519 \t      0.8342\n",
      " 0.001\t\t    256\t       1/3 \t 2.0175 \t    0.3111 \t    1.3762 \t      0.7288\n",
      " 0.001\t\t    256\t       2/3 \t 1.5043 \t    0.5674 \t    0.9702 \t      0.7994\n",
      " 0.001\t\t    256\t       3/3 \t 1.2050 \t    0.6710 \t    0.7556 \t      0.8333\n",
      " 0.001\t\t    512\t       1/3 \t 1.9831 \t    0.3309 \t    1.2880 \t      0.7352\n",
      " 0.001\t\t    512\t       2/3 \t 1.4658 \t    0.5788 \t    0.9219 \t      0.8079\n",
      " 0.001\t\t    512\t       3/3 \t 1.1913 \t    0.6722 \t    0.7274 \t      0.8417\n",
      " 0.01\t\t    32\t       1/3 \t 1.0407 \t    0.6990 \t    0.3721 \t      0.8956\n",
      " 0.01\t\t    32\t       2/3 \t 0.5126 \t    0.8570 \t    0.2830 \t      0.9145\n",
      " 0.01\t\t    32\t       3/3 \t 0.4155 \t    0.8813 \t    0.2437 \t      0.9273\n",
      " 0.01\t\t    64\t       1/3 \t 1.0487 \t    0.6956 \t    0.3740 \t      0.8990\n",
      " 0.01\t\t    64\t       2/3 \t 0.5177 \t    0.8551 \t    0.2781 \t      0.9175\n",
      " 0.01\t\t    64\t       3/3 \t 0.4081 \t    0.8842 \t    0.2426 \t      0.9279\n",
      " 0.01\t\t    128\t       1/3 \t 1.0568 \t    0.6912 \t    0.3698 \t      0.8970\n",
      " 0.01\t\t    128\t       2/3 \t 0.5169 \t    0.8540 \t    0.2772 \t      0.9169\n",
      " 0.01\t\t    128\t       3/3 \t 0.4159 \t    0.8815 \t    0.2419 \t      0.9282\n",
      " 0.01\t\t    256\t       1/3 \t 1.0295 \t    0.6965 \t    0.3808 \t      0.8958\n",
      " 0.01\t\t    256\t       2/3 \t 0.5216 \t    0.8544 \t    0.2765 \t      0.9174\n",
      " 0.01\t\t    256\t       3/3 \t 0.4110 \t    0.8843 \t    0.2492 \t      0.9252\n",
      " 0.01\t\t    512\t       1/3 \t 1.0484 \t    0.6949 \t    0.3778 \t      0.8933\n",
      " 0.01\t\t    512\t       2/3 \t 0.5227 \t    0.8544 \t    0.2848 \t      0.9160\n",
      " 0.01\t\t    512\t       3/3 \t 0.4168 \t    0.8813 \t    0.2516 \t      0.9243\n",
      " 0.1\t\t    32\t       1/3 \t 0.5667 \t    0.8271 \t    0.2431 \t      0.9257\n",
      " 0.1\t\t    32\t       2/3 \t 0.3260 \t    0.9026 \t    0.1828 \t      0.9471\n",
      " 0.1\t\t    32\t       3/3 \t 0.2724 \t    0.9190 \t    0.1689 \t      0.9480\n",
      " 0.1\t\t    64\t       1/3 \t 0.5642 \t    0.8278 \t    0.2528 \t      0.9235\n",
      " 0.1\t\t    64\t       2/3 \t 0.3325 \t    0.9026 \t    0.1779 \t      0.9460\n",
      " 0.1\t\t    64\t       3/3 \t 0.2722 \t    0.9196 \t    0.1777 \t      0.9490\n",
      " 0.1\t\t    128\t       1/3 \t 0.5735 \t    0.8244 \t    0.2334 \t      0.9301\n",
      " 0.1\t\t    128\t       2/3 \t 0.3254 \t    0.9044 \t    0.1794 \t      0.9456\n",
      " 0.1\t\t    128\t       3/3 \t 0.2737 \t    0.9200 \t    0.1549 \t      0.9540\n",
      " 0.1\t\t    256\t       1/3 \t 0.5670 \t    0.8250 \t    0.2233 \t      0.9311\n",
      " 0.1\t\t    256\t       2/3 \t 0.3247 \t    0.9036 \t    0.1877 \t      0.9423\n",
      " 0.1\t\t    256\t       3/3 \t 0.2712 \t    0.9201 \t    0.1626 \t      0.9511\n",
      " 0.1\t\t    512\t       1/3 \t 0.5833 \t    0.8202 \t    0.2657 \t      0.9206\n",
      " 0.1\t\t    512\t       2/3 \t 0.3206 \t    0.9037 \t    0.1812 \t      0.9440\n",
      " 0.1\t\t    512\t       3/3 \t 0.2701 \t    0.9199 \t    0.1539 \t      0.9524\n",
      " 0.5\t\t    32\t       1/3 \t 0.6364 \t    0.8022 \t    0.2378 \t      0.9280\n",
      " 0.5\t\t    32\t       2/3 \t 0.3101 \t    0.9082 \t    0.1706 \t      0.9479\n",
      " 0.5\t\t    32\t       3/3 \t 0.2468 \t    0.9284 \t    0.1407 \t      0.9586\n",
      " 0.5\t\t    64\t       1/3 \t 0.6355 \t    0.8028 \t    0.2198 \t      0.9319\n",
      " 0.5\t\t    64\t       2/3 \t 0.3057 \t    0.9100 \t    0.1627 \t      0.9515\n",
      " 0.5\t\t    64\t       3/3 \t 0.2511 \t    0.9280 \t    0.1618 \t      0.9501\n",
      " 0.5\t\t    128\t       1/3 \t 0.6437 \t    0.7999 \t    0.2236 \t      0.9329\n",
      " 0.5\t\t    128\t       2/3 \t 0.3112 \t    0.9071 \t    0.1803 \t      0.9462\n",
      " 0.5\t\t    128\t       3/3 \t 0.2535 \t    0.9251 \t    0.1547 \t      0.9519\n",
      " 0.5\t\t    256\t       1/3 \t 0.6362 \t    0.8004 \t    0.2358 \t      0.9261\n",
      " 0.5\t\t    256\t       2/3 \t 0.3041 \t    0.9111 \t    0.1793 \t      0.9439\n",
      " 0.5\t\t    256\t       3/3 \t 0.2500 \t    0.9277 \t    0.1490 \t      0.9519\n",
      " 0.5\t\t    512\t       1/3 \t 0.6336 \t    0.8027 \t    0.2685 \t      0.9170\n",
      " 0.5\t\t    512\t       2/3 \t 0.3107 \t    0.9063 \t    0.1835 \t      0.9433\n",
      " 0.5\t\t    512\t       3/3 \t 0.2502 \t    0.9255 \t    0.1522 \t      0.9545\n",
      " 1.0\t\t    32\t       1/3 \t 0.7569 \t    0.7635 \t    0.2355 \t      0.9282\n",
      " 1.0\t\t    32\t       2/3 \t 0.3454 \t    0.8982 \t    0.1879 \t      0.9426\n",
      " 1.0\t\t    32\t       3/3 \t 0.2754 \t    0.9206 \t    0.1617 \t      0.9500\n",
      " 1.0\t\t    64\t       1/3 \t 0.7068 \t    0.7796 \t    0.2342 \t      0.9292\n",
      " 1.0\t\t    64\t       2/3 \t 0.3215 \t    0.9055 \t    0.1798 \t      0.9467\n",
      " 1.0\t\t    64\t       3/3 \t 0.2663 \t    0.9226 \t    0.1539 \t      0.9525\n",
      " 1.0\t\t    128\t       1/3 \t 0.7201 \t    0.7766 \t    0.2329 \t      0.9290\n",
      " 1.0\t\t    128\t       2/3 \t 0.3316 \t    0.9030 \t    0.1724 \t      0.9481\n",
      " 1.0\t\t    128\t       3/3 \t 0.2667 \t    0.9238 \t    0.1563 \t      0.9523\n",
      " 1.0\t\t    256\t       1/3 \t 0.7127 \t    0.7811 \t    0.2645 \t      0.9204\n",
      " 1.0\t\t    256\t       2/3 \t 0.3238 \t    0.9062 \t    0.1695 \t      0.9471\n",
      " 1.0\t\t    256\t       3/3 \t 0.2679 \t    0.9224 \t    0.1503 \t      0.9537\n",
      " 1.0\t\t    512\t       1/3 \t 0.7452 \t    0.7693 \t    0.2337 \t      0.9298\n",
      " 1.0\t\t    512\t       2/3 \t 0.3306 \t    0.9039 \t    0.1845 \t      0.9446\n",
      " 1.0\t\t    512\t       3/3 \t 0.2757 \t    0.9223 \t    0.1666 \t      0.9513\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "# Load the dataset\n",
    "df = pd.read_csv('train.csv')\n",
    "# Step 2: Splitting the Dataset into features\n",
    "X = df.drop('label', axis=1) # Inputs (Features) , axis = 1 means to drop only one coloumn \n",
    "y = df['label']  # Output => (Target)\n",
    "# Step 3: Splitting the dataset into 80% Training and 20% Validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to your data and transform it\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_val_normalized = scaler.transform(X_val)\n",
    "# Create DataFrames with the normalized data\n",
    "df_train_normalized = pd.DataFrame(X_train_normalized, columns=X_train.columns)\n",
    "df_val_normalized = pd.DataFrame(X_val_normalized, columns=X_val.columns)\n",
    "\n",
    "# Define a custom PyTorch dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features.values, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels.values, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "# Create datasets and data loaders for training and validation\n",
    "train_dataset = CustomDataset(df_train_normalized, y_train)\n",
    "val_dataset = CustomDataset(df_val_normalized, y_val)\n",
    "\n",
    "batch_size = 64  # You can adjust this based on your needs\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#creation of an archotecture\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class DigitRecModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size, dropout_rate=0.5):\n",
    "        super(DigitRecModel, self).__init__()\n",
    "\n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.norm1 = nn.LayerNorm(hidden_size1)  # Add layer normalization\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.norm2 = nn.LayerNorm(hidden_size2)  # Add layer normalization\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the forward pass\n",
    "        x = self.dropout1(self.relu1(self.norm1(self.fc1(x))))\n",
    "        x = self.dropout2(self.relu2(self.norm2(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "input_size = 28 * 28  # Assuming images are 28x28 pixels\n",
    "output_size = 10  # Number of classes (digits 0-9)\n",
    "dropout_rate = 0.5  \n",
    "hidden_size1 = 256  \n",
    "hidden_size2 = 128\n",
    "\n",
    "\n",
    "\n",
    "simple_model = DigitRecModel(input_size,hidden_size1,hidden_size2, output_size, dropout_rate)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Assume you have simple_model, train_loader, and val_loader defined\n",
    "\n",
    "# losses and accuracy\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Experiment with different learning rates and batch sizes\n",
    "learning_rates = [0.001, 0.01, 0.1, 0.5, 1.0]\n",
    "batch_sizes = [32, 64, 128, 256, 512]\n",
    "print(\"| Learning Rate | Batch Size | Epoch | Training Loss | Training Accuracy | Validation Loss | Validation Accuracy |\")\n",
    "for lr in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        # Define model, loss function, and optimizer with the current learning rate\n",
    "        simple_model = DigitRecModel(input_size,hidden_size1,hidden_size2, output_size, dropout_rate) # Replace YourModel with the actual model class\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(simple_model.parameters(), lr=lr)\n",
    "\n",
    "        epochs = 3\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            simple_model.train()  # Set the model to training mode\n",
    "\n",
    "            # Training\n",
    "            correct_train = 0\n",
    "            total_train = 0\n",
    "            running_train_loss = 0.0\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = simple_model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_train += labels.size(0)\n",
    "                correct_train += (predicted == labels).sum().item()\n",
    "                running_train_loss += loss.item()\n",
    "\n",
    "            train_accuracy = correct_train / total_train\n",
    "            train_losses.append(running_train_loss / len(train_loader))\n",
    "            train_accuracies.append(train_accuracy)\n",
    "\n",
    "            # Validation\n",
    "            simple_model.eval()  # Set the model to evaluation mode\n",
    "            correct_val = 0\n",
    "            total_val = 0\n",
    "            running_val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in val_loader:\n",
    "                    outputs = simple_model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total_val += labels.size(0)\n",
    "                    correct_val += (predicted == labels).sum().item()\n",
    "                    running_val_loss += loss.item()\n",
    "\n",
    "            val_accuracy = correct_val / total_val\n",
    "            val_losses.append(running_val_loss / len(val_loader))\n",
    "            val_accuracies.append(val_accuracy)\n",
    "\n",
    "            # Print the loss and accuracy after each epoch for the current learning rate and batch size\n",
    "           \n",
    "\n",
    "            print(f' {lr}\\t\\t    {batch_size}'\n",
    "                  f'\\t       {epoch + 1}/{epochs} '\n",
    "                  f'\\t {train_losses[-1]:.4f} \\t    {train_accuracy:.4f} '\n",
    "                  f'\\t    {val_losses[-1]:.4f} \\t      {val_accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
